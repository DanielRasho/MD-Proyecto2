{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f67cd8",
   "metadata": {},
   "source": [
    "# Proyecto 2 \n",
    "## Support Vector Machines (SVM)\n",
    "github: [link aqui](https://github.com/DanielRasho/MD-Proyecto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f128d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import random\n",
    "\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical Analysis\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "# Machine Learning - Scikit-learn\n",
    "from sklearn import datasets, metrics, tree\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.metrics import accuracy_score ,precision_score,recall_score,f1_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, explained_variance_score, mean_absolute_error, ConfusionMatrixDisplay,\n",
    "    mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score,accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    ")\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV, ShuffleSplit, cross_validate, train_test_split\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "# Model Evaluation & Utilities\n",
    "import setuptools.dist\n",
    "from yellowbrick.regressor import ResidualsPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1237f23",
   "metadata": {},
   "source": [
    "## Cargado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed8af1",
   "metadata": {},
   "source": [
    "## Limpieza de datos\n",
    "\n",
    "Primero, se realiza una descripción del dataset para obtener un resumen estadístico de los datos. Esto nos permite identificar la distribución de las variables, sus valores mínimos y máximos, la media, la mediana y la desviación estándar. Además, nos ayuda a detectar posibles valores atípicos y comprender mejor la escala de los datos antes de realizar cualquier limpieza o transformación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
